# Welcome

I trust that you can glean valuable insights from this portfolio and apply them to real-world projects. Within these materials, I have endeavored to present essential principles, best practices, and guidelines that prove beneficial when engaged in project development as a Data Engineer, Data Analyst, or Analytics Engineer.

In accordance with the **"Pragmatic Starter Kit"** outlined in "The Pragmatic Programmer" book:
1. Version Control
2. Regression Testing
3. Full Automation

With that said let's dive in... 🏊‍♂️

## What are you going to find here?

- Version-Control everything whenever possible
- Automation ( Github Actions , pre-commit hooks, Azure DevOps )
- Function Programming paradigm in Data Engineering projects
- Python **typing hints** are helpful for future yourself or another developer
- Use **Docstrings** in Python Functions ( Google or Numpy )
- Documentation made easy with **MkDocs** + **MkDocs Materials** + Community plugins being deployed to `GitHub Pages`
- Importance of Design Docs and RFC's for Data Projects.
- Format your code.A well formatted code + sorted imports are a matter of organization, **Isort** and **Black** do it for us.
- Importance of Tests and how **Pytest** and their plenty of plugins facilitates our life with `fixture`, `marks`, and `conftest` file
- Pattern Given-When-Then derived from BDD in Tests Cases
- Coverage of code with **pytest-cov** and **coverage**
- DRY Principle ( Avoid repetition in your code )
- and many more +++

## Technology Tools

- `Poetry` for dependency management and packaging.
- How Databricks stack streamline the process of creating scalable data engineering projects locally IDE ( in my case VSCode ) and run remotely.
- How dbx and the newest released `Databricks Asset Bundles` makes easy to manipulate Databricks Assets.
- Delta Live Tables + Autoloader a combination made in heaven.


To sum up, there is no jack of all trades, always you will need specific tools to accomplish a goal.
However good principles applied and well solidified, avoid big headaches in the future, be for a change request, add new use cases, transfer of ownership or onboarding a new joiner.

> Check the [Documentation]() in GitHub Pages


---

# Pics to give you a flavor

## Jobs in CI/CD

![ci_cd](./docs/assets/ci_cd.png)
---
## Coverage
![coverage](./docs/assets/coverage.png)
---
## Deploy
![deploy](./docs/assets/deploy.png)
---
## Graphic and Lineage from Delta Live Tables
![dlt](./docs/assets/delta_live_tables.png)
---
## Workflow in Databricks
![workflows](./docs/assets/workflows.png)
---
## The quote
![request_quote](./docs/assets/request_quote.png)
---
## Catalog and Delta Tables
![delta_in_catalog](./docs/assets/delta_tables_in_catalog.png)
---
## Delta Table Properties defined in the pipeline
![delta_table_properties](./docs/assets/delta_properties.png)



# Everything showed in the images, you can find on the repo and more nitty-gritty details in documentation
# Enjoy  💕 💞

